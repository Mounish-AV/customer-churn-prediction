# Step-by-Step Testing Guide

## ðŸš€ Quick Test Commands

### Step 1: Verify Python and Dependencies
```bash
# Check Python version (should be 3.8+)
python --version

# Check if key packages are installed
python -c "import pandas, numpy, sklearn, xgboost, yaml; print('âœ… All dependencies installed!')"
```

### Step 2: Verify Data is Available
```bash
# Check if data file exists
ls -lh data/raw/telco_customer_churn.csv

# Check number of rows
wc -l data/raw/telco_customer_churn.csv
```

### Step 3: Run Basic Test (Fast - ~5 seconds)
```bash
# This tests data loading, validation, and preprocessing
python test_basic.py
```

### Step 4: Run Full Pipeline Test (Complete - ~30 seconds)
```bash
# This runs the entire ML pipeline and shows accuracy
python test_pipeline.py
```

### Step 5: Check Results
```bash
# View the final results
tail -20 test_pipeline.py

# Or run and see only the final summary
python test_pipeline.py 2>&1 | tail -30
```

## ðŸ“Š What to Expect

### Basic Test Output:
```
âœ“ Configuration loaded
âœ“ Raw data loaded: (7043, 21)
âœ“ Validation passed
âœ“ Data cleaned
âœ“ Missing values handled
âœ“ Data split successfully
All basic tests passed successfully!
```

### Full Pipeline Output (Final Results):
```
============================================================
Pipeline completed successfully!
============================================================

Best Model: logistic_regression
Test ROC-AUC: 0.8574      â† Main accuracy metric (85.74%)
Test Accuracy: 0.8136     â† Overall accuracy (81.36%)
Test Precision: 0.6844    â† Precision (68.44%)
Test Recall: 0.5500       â† Recall (55.00%)
Test F1-Score: 0.6099     â† F1 Score (60.99%)
```

## ðŸŽ¯ Understanding the Metrics

- **ROC-AUC (0.8574)**: Overall model quality - **85.74% is EXCELLENT!**
- **Accuracy (0.8136)**: 81.36% of predictions are correct
- **Precision (0.6844)**: 68.44% of predicted churners actually churn
- **Recall (0.5500)**: Model catches 55% of actual churners
- **F1-Score (0.6099)**: Balance between precision and recall

## ðŸ” Check Generated Files

### View trained models:
```bash
ls -lh models/production/
```

### View visualizations:
```bash
ls -lh reports/figures/
```

### Open a visualization (if you have image viewer):
```bash
# On Linux
xdg-open reports/figures/roc_curve.png

# Or just list them
ls reports/figures/*.png
```

## ðŸ› Troubleshooting

### If you get "Module not found":
```bash
pip install -r requirements.txt
```

### If data file is missing:
```bash
python download_data.py
```

### If you want to see detailed logs:
```bash
# Run with full output
python test_pipeline.py
```

## âœ… Success Criteria

You should see:
- âœ… All tests pass without errors
- âœ… ROC-AUC > 0.80 (we got 0.8574!)
- âœ… Model saved to `models/production/best_model.pkl`
- âœ… Visualizations in `reports/figures/`

## ðŸŽ‰ Quick One-Liner Test

```bash
# Run everything and show final results
python test_pipeline.py 2>&1 | grep -A 10 "Pipeline completed successfully"
```

