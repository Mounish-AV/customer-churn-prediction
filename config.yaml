# Project Configuration
project:
  name: customer-churn-prediction
  version: 1.0.0
  description: End-to-end ML project for customer churn prediction

# Data Configuration
data:
  raw_dir: data/raw
  processed_dir: data/processed
  external_dir: data/external
  dataset_name: telco_customer_churn.csv
  kaggle_dataset: blastchar/telco-customer-churn

# Data Splitting
split:
  test_size: 0.15
  validation_size: 0.15
  random_state: 42
  stratify: true

# Feature Engineering
features:
  categorical_features:
    - gender
    - SeniorCitizen
    - Partner
    - Dependents
    - PhoneService
    - MultipleLines
    - InternetService
    - OnlineSecurity
    - OnlineBackup
    - DeviceProtection
    - TechSupport
    - StreamingTV
    - StreamingMovies
    - Contract
    - PaperlessBilling
    - PaymentMethod
    - tenure_group  # Created during feature engineering

  numerical_features:
    - tenure
    - MonthlyCharges
    - TotalCharges

  target: Churn

  encoding:
    method: onehot  # onehot, label, target
    handle_unknown: ignore

# Preprocessing
preprocessing:
  handle_missing:
    strategy: median  # mean, median, mode, drop

  scaling:
    method: standard  # standard, minmax, robust

  outlier_detection:
    method: iqr  # iqr, zscore, isolation_forest
    threshold: 3

# Model Configuration
models:
  baseline:
    name: LogisticRegression
    params:
      random_state: 42
      max_iter: 1000

  logistic_regression:
    name: LogisticRegression
    params:
      random_state: 42
      max_iter: 1000
      C: 1.0
      penalty: l2

  random_forest:
    name: RandomForestClassifier
    params:
      random_state: 42
      n_estimators: 100
      max_depth: 10
      min_samples_split: 5
      min_samples_leaf: 2

  xgboost:
    name: XGBClassifier
    params:
      random_state: 42
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8

# Hyperparameter Tuning
tuning:
  method: grid_search  # grid_search, random_search, bayesian
  cv_folds: 5
  scoring: roc_auc
  n_iter: 50  # for random_search

  param_grids:
    random_forest:
      n_estimators: [50, 100, 200]
      max_depth: [5, 10, 15, 20]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]

    xgboost:
      n_estimators: [50, 100, 200]
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1, 0.3]
      subsample: [0.7, 0.8, 0.9]

# Evaluation Metrics
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc
    - confusion_matrix

  threshold: 0.5

  business_metrics:
    customer_lifetime_value: 1000
    retention_cost: 100
    acquisition_cost: 500

# Model Selection
selection:
  primary_metric: roc_auc
  minimize: false

# Model Persistence
persistence:
  models_dir: models
  baseline_dir: models/baseline
  experiments_dir: models/experiments
  production_dir: models/production

  save_format: pkl  # pkl, joblib, h5

# Logging
logging:
  level: INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: logs/app.log

# API Configuration
api:
  host: 0.0.0.0
  port: 8000
  reload: true
  workers: 4

# Monitoring
monitoring:
  enable_drift_detection: true
  drift_threshold: 0.05
  performance_threshold: 0.75
  alert_email: admin@example.com

# Deployment
deployment:
  model_version: v1
  endpoint: /predict
  health_check: /health
  batch_size: 100
