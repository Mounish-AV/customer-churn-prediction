# Customer Churn Prediction

![Status](https://img.shields.io/badge/status-production%20ready-brightgreen)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![ROC-AUC](https://img.shields.io/badge/ROC--AUC-85.74%25-success)

A complete, production-ready machine learning system to predict customer churn for telecommunications companies. Achieves **85.74% ROC-AUC** on test data.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Methodology](#methodology)
- [Results](#results)
- [Technologies Used](#technologies-used)
- [Contributing](#contributing)
- [License](#license)
- [Author](#author)
- [Acknowledgments](#acknowledgments)

## ğŸ¯ Overview

This project identifies customers at risk of churning (leaving the service) using machine learning techniques. The system is **fully tested and production-ready** with excellent performance metrics.

**Business Impact:**
- **85.74% ROC-AUC** - Excellent discrimination between churners and non-churners
- **68.44% Precision** - High confidence in churn predictions
- **55% Recall** - Catches majority of at-risk customers
- Enables targeted retention campaigns with measurable ROI

**Key Features:**
- âœ… Complete end-to-end ML pipeline (tested and verified)
- âœ… 3 ML algorithms trained and compared (Logistic Regression, Random Forest, XGBoost)
- âœ… Production model deployed and ready to use
- âœ… Comprehensive data validation and preprocessing
- âœ… Advanced feature engineering (10 engineered features)
- âœ… Automated model evaluation and selection
- âœ… Visualization and reporting capabilities

## ğŸ“Š Dataset

We use the [Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) containing:
- 7,043 customer records
- 21 features (demographics, services, account info)
- Binary target: Churn (Yes/No)

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+ (tested with Python 3.12.7)
- pip or conda

### Installation & Setup

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Download dataset from Kaggle
# Visit: https://www.kaggle.com/datasets/blastchar/telco-customer-churn
# Download and place in: data/raw/telco_customer_churn.csv

# 3. Run the pipeline (see src/ modules for usage)
```

**The system has been tested and validated with:**
```
âœ… Best Model: Logistic Regression
âœ… Test ROC-AUC: 0.8574 (85.74%)
âœ… Test Accuracy: 0.8136 (81.36%)
âœ… Production model: models/production/best_model.pkl
```

### Making Predictions

```python
from src.models.predict_model import load_production_model, predict_proba
import pandas as pd

# Load the trained model
model = load_production_model('best_model')

# Load your data
new_customers = pd.read_csv('your_data.csv')

# Make predictions
churn_probabilities = predict_proba(model, new_customers)
```

> ğŸ“– For detailed usage examples, see [QUICK_START.md](QUICK_START.md)

## ğŸ“ Project Structure

```
CustomerChurn/
â”œâ”€â”€ config.yaml                    # Complete configuration
â”œâ”€â”€ requirements.txt               # All dependencies
â”œâ”€â”€ download_data.py               # Data download script
â”œâ”€â”€ test_basic.py                  # Basic pipeline test âœ…
â”œâ”€â”€ test_pipeline.py               # Full pipeline test âœ…
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Raw dataset (7,043 records)
â”‚   â””â”€â”€ processed/                 # Train/val/test splits
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline/                  # Baseline models
â”‚   â”œâ”€â”€ experiments/               # All trained models
â”‚   â””â”€â”€ production/                # Best model (85.74% ROC-AUC)
â”‚       â”œâ”€â”€ best_model.pkl         # Production model
â”‚       â”œâ”€â”€ scaler.pkl             # Feature scaler
â”‚       â””â”€â”€ feature_names.pkl      # Feature list
â”‚
â”œâ”€â”€ reports/figures/               # Visualizations
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â””â”€â”€ feature_importance.png
â”‚
â””â”€â”€ src/                           # Source code (11 modules)
    â”œâ”€â”€ data/                      # Loading, validation, preprocessing
    â”œâ”€â”€ features/                  # Feature engineering
    â”œâ”€â”€ models/                    # Training, prediction, evaluation
    â”œâ”€â”€ utils/                     # Logging, helpers
    â””â”€â”€ visualization/             # Plotting functions
```

> ğŸ“– For complete file inventory, see [FILES_CREATED.md](FILES_CREATED.md)

## ğŸ”„ Pipeline Architecture

The system implements a complete ML pipeline with the following stages:

### 1. Data Loading & Validation
- Load 7,043 customer records from CSV
- Validate data quality (missing values, duplicates, distributions)
- Check for data integrity issues

### 2. Data Preprocessing
- Clean data and handle missing values (11 imputed)
- Remove outliers using IQR method
- Split into train (70%), validation (15%), test (15%)
- Stratified sampling to maintain class balance

### 3. Feature Engineering
- **Tenure Groups**: Categorize customer tenure
- **Service Features**: Total services, internet/phone flags
- **Contract Features**: Month-to-month indicator, paperless billing
- **Charge Features**: Average charges, charge ratios
- **Demographic Features**: Family status, senior indicators
- **Result**: 21 â†’ 42 features after engineering and encoding

### 4. Model Training & Selection
- Train 3 algorithms: Logistic Regression, Random Forest, XGBoost
- Compare models on validation set using ROC-AUC
- Select best model (Logistic Regression: 83.66% val ROC-AUC)
- Evaluate on held-out test set (85.74% test ROC-AUC)

### 5. Model Deployment
- Save production model with scaler and feature names
- Generate visualizations (confusion matrix, ROC curve)
- Ready for batch or real-time predictions

## ğŸ“ˆ Results

### Model Performance (Test Set)

**Best Model: Logistic Regression**

| Metric | Score | Interpretation |
|--------|-------|----------------|
| **ROC-AUC** | **85.74%** | â­ Excellent discrimination ability |
| **Accuracy** | **81.36%** | Overall prediction accuracy |
| **Precision** | **68.44%** | 68% of predicted churners actually churn |
| **Recall** | **55.00%** | Catches 55% of actual churners |
| **F1-Score** | **60.99%** | Balanced precision-recall metric |

### Model Comparison (Validation Set)

| Model | Accuracy | Precision | Recall | F1 | ROC-AUC |
|-------|----------|-----------|--------|-----|---------|
| **Logistic Regression** | 79.75% | 65.58% | 50.18% | 56.85% | **83.66%** âœ… |
| Random Forest | 79.94% | 67.16% | 48.04% | 56.02% | 82.81% |
| XGBoost | 79.19% | 63.44% | 51.25% | 56.69% | 82.72% |

**Winner**: Logistic Regression selected based on highest ROC-AUC

### Business Impact

With this model, you can:
- ğŸ¯ **Identify high-risk customers** with 85.74% accuracy (ROC-AUC)
- ğŸ’° **Target retention campaigns** to 68% true churners (Precision)
- ğŸ“Š **Reduce churn** by proactively reaching 55% of at-risk customers (Recall)
- ğŸ’¡ **Optimize marketing spend** by focusing on customers most likely to churn

> ğŸ” For complete analysis, see [FINAL_SUMMARY.md](FINAL_SUMMARY.md)

## ğŸ› ï¸ Technologies Used

- **ML Libraries:** scikit-learn (1.5.1), XGBoost (3.1.2)
- **Data Processing:** Pandas (2.3.3), NumPy (1.26.4)
- **Visualization:** Matplotlib (3.9.2), Seaborn (0.13.2)
- **Configuration:** PyYAML
- **Python Version:** 3.8+ (tested with 3.12.7)

## ğŸ“š Documentation

- **[GETTING_STARTED.md](GETTING_STARTED.md)** - First-time user orientation guide
- **[QUICK_START.md](QUICK_START.md)** - 5-minute getting started guide
- **[FINAL_SUMMARY.md](FINAL_SUMMARY.md)** - Complete project summary with results
- **[PROJECT_STATUS.md](PROJECT_STATUS.md)** - Detailed implementation status
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - Contribution guidelines

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Mounish V**
- GitHub: [@Mounish-AV](https://github.com/Mounish-AV)

## ğŸ™ Acknowledgments

- Telco Customer Churn dataset from Kaggle
- CRISP-DM methodology documentation
- Open source community

---

â­ If you find this project helpful, please consider giving it a star!
